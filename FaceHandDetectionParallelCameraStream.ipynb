{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438aa03a",
   "metadata": {},
   "source": [
    "## Running two ML models at the same time\n",
    "This notebook is an example how to run two models side-by-side and combine results of both models. A video stream from a local camera is processed by the hand and face detection models. Combined result is then displayed.\n",
    "OpenCV is required to run this sample.\n",
    "\n",
    "This script works with \n",
    "\n",
    "0. DeGirum Cloud Server, \n",
    "1. AI server equipped with DeGirum ORCA accelerator shared via Peer-to-Peer VPN, \n",
    "2. AI server equipped with DeGirum ORCA accelerator running in local network and \n",
    "3. AI server equipped with DeGirum ORCA accelerator running on the same machine as this code. \n",
    "\n",
    "To try different options, you just need to change the __model_zoo_option_index__ in the code below. \n",
    "\n",
    "The script needs a web camera connected to the machine running this code. The __camera_index__ also needs to be specified in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53050e-8e74-454f-b4eb-4883a8f02ca9",
   "metadata": {},
   "source": [
    "### Specify your model zoo option and camera index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9dd69-dcdc-4fc6-8c8d-0d8771eb5d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo_option_list = ['DEGIRUM_CLOUD_SERVER', 'P2P_VPN_SERVER', 'LOCAL_NETWORK_SERVER', 'LOCALHOST']\n",
    "model_zoo_option_index=1\n",
    "camera_index=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0c86d-0e48-4116-9f7d-61dc1a08f8fa",
   "metadata": {},
   "source": [
    "### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import cv2 # OpenCV\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "def show(img, capt = \"<image>\"):\n",
    "    # show opencv image\n",
    "    cv2.imshow(capt, img)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('x') or key == ord('q'):\n",
    "        raise KeyboardInterrupt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000fb0e-fc9e-4a82-af22-9f4188309fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs_loaded=load_dotenv()\n",
    "model_zoo_option=model_zoo_option_list[model_zoo_option_index]\n",
    "if model_zoo_option=='DEGIRUM_CLOUD_SERVER':\n",
    "    zoo = dg.connect_model_zoo(os.getenv('DEGIRUM_CLOUD_SERVER_ADDRESS'), token=os.getenv('DEGIRUM_CLOUD_TOKEN'))\n",
    "elif model_zoo_option=='P2P_VPN_SERVER':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('P2P_VPN_SERVER_ADDRESS'))\n",
    "elif model_zoo_option=='LOCAL_NETWORK_SERVER':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('LOCAL_NETWORK_SERVER_ADDRESS'))\n",
    "elif model_zoo_option=='LOCALHOST':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('LOCAL_HOST_ADDRESS'))\n",
    "else:\n",
    "    print('Model zoo option not supported \\n')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33012fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "hand_det_model = zoo.load_model(\"yolo_v5s_hand_det--512x512_quant_n2x_orca_1\")\n",
    "face_det_model = zoo.load_model(\"yolo_v5s_face_det--512x512_quant_n2x_orca_1\")\n",
    "\n",
    "# select OpenCV backend: needed to have overlay image in OpenCV format\n",
    "hand_det_model.image_backend = 'opencv'\n",
    "hand_det_model._model_parameters.InputImgFmt=['JPEG']\n",
    "hand_det_model.input_numpy_colorspace='BGR'\n",
    "\n",
    "face_det_model.image_backend = 'opencv' \n",
    "face_det_model._model_parameters.InputImgFmt=['JPEG']\n",
    "face_det_model.input_numpy_colorspace='BGR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eccd95-e365-42d6-86d3-1e2e017744ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open video stream from local camera \n",
    "stream = cv2.VideoCapture(camera_index)\n",
    "if (stream.isOpened()== False):\n",
    "    print(\"Error opening video stream\")\n",
    "else:\n",
    "    print(\"Succesful in opening video stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define iterator function, which returns frames from camera \n",
    "def source(idx):\n",
    "    # idx is the index of a buffer\n",
    "    N = 2 # number of buffers\n",
    "    bufs = [[]] * N\n",
    "    assert idx < N\n",
    "    while True:\n",
    "        if len(bufs[idx]) == 0: # this buffer is empty: get frame from camera and add to all buffers\n",
    "            ret, frame = stream.read()\n",
    "            for s in bufs:\n",
    "                s.insert(0, frame)\n",
    "        yield bufs[idx].pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93242ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # run person detection model on a camera stream\n",
    "    for hands, faces in zip(hand_det_model.predict_batch(source(0)), face_det_model.predict_batch(source(1))):\n",
    "\n",
    "        hands._inference_results += faces._inference_results\n",
    "        show(hands.image_overlay, \"Hands and Faces\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass # ignore KeyboardInterrupt errors\n",
    "finally:\n",
    "    cv2.destroyAllWindows() # close OpenCV windows\n",
    "stream.release() # release camera stream"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dg_pysdk)",
   "language": "python",
   "name": "dg_pysdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
