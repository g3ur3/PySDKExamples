{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08e7226",
   "metadata": {},
   "source": [
    "## Simple example script illustrating object detection\n",
    "This notebook is one of the most simplest examples how to use DeGirum PySDK to do AI inference of a graphical file using  object detection model.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. [DeGirum Cloud Platform](https://cs.degirum.com),\n",
    "1. DeGirum-hosted AI server node shared via Peer-to-Peer VPN,\n",
    "1. AI server node hosted by you in your local network,\n",
    "1. AI server running on your local machine,\n",
    "1. DeGirum ORCA accelerator directly installed on your local machine.\n",
    "\n",
    "To try different options, you just need to change the `inference_option` in the code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7b0e9-e62d-4d7e-a777-8cf7622a1370",
   "metadata": {},
   "source": [
    "### Specify where do you want to run your inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75c83e-433a-4c27-ac85-c1a9185013f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_option = 1  # <<< change it according to your needs selecting from the list in the header comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4549b06-567f-4cdb-8b82-bb4ef5858f2f",
   "metadata": {},
   "source": [
    "### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import mytools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to model zoo according to selected inference option\n",
    "zoo = mytools.connect_model_zoo(inference_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f4a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list all AI models available for inference\n",
    "zoo.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2baec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load AI model 'ssd_mobilenet_v2' for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "model = zoo.load_model(\"mobilenet_v2_ssd_coco--300x300_quant_n2x_orca_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62046c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get class labels dictionary\n",
    "label_dictionary = model.label_dictionary\n",
    "\n",
    "# print it\n",
    "for id, label in sorted(label_dictionary.items()):\n",
    "    print(f\"{id:3}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e9d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get model info\n",
    "model_info = model.model_info\n",
    "\n",
    "# print all model info attributes and their values\n",
    "for attr in dir(model_info):\n",
    "    value = getattr(model_info, attr)\n",
    "    print(f\"{attr:25}= {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27299231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure some result visualization parameters (optional step)\n",
    "model.image_backend = \"pil\" # use PIL as image rendering backend\n",
    "model.overlay_show_probabilities = True # show class probabilities on overlay image\n",
    "model.overlay_font_scale = 1.5 # increase font size for overlay image labels\n",
    "model.overlay_alpha = 1 # set minimum transparency for overlay image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03954556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform AI model inference on given image file (assuming current direcory is where this notebook is located)\n",
    "res = model(\"./images/TwoCats.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb207347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results of inference\n",
    "print(res) # numeric results\n",
    "res.image_overlay # graphical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86611f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
