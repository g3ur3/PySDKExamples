{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08e7226",
   "metadata": {},
   "source": [
    "## Simple example script illustrating object detection\n",
    "This notebook is one of the most simplest examples how to use DeGirum PySDK to do AI inference of a graphical file using  object detection model.\n",
    "\n",
    "This script works with \n",
    "\n",
    "0. DeGirum Cloud Server, \n",
    "1. AI server equipped with DeGirum ORCA accelerator shared via Peer-to-Peer VPN, \n",
    "2. AI server equipped with DeGirum ORCA accelerator running in local network and \n",
    "3. AI server equipped with DeGirum ORCA accelerator running on the same machine as this code. \n",
    "\n",
    "To try different options, you just need to change the __model_zoo_option_index__ in the code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7b0e9-e62d-4d7e-a777-8cf7622a1370",
   "metadata": {},
   "source": [
    "### Specify your model zoo option here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75c83e-433a-4c27-ac85-c1a9185013f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo_option_list = ['DEGIRUM_CLOUD_SERVER', 'P2P_VPN_SERVER', 'LOCAL_NETWORK_SERVER', 'LOCALHOST']\n",
    "model_zoo_option_index=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DeGirum PySDK\n",
    "import degirum as dg\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ce577-64c0-4dae-8c93-ec91be1d0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs_loaded=load_dotenv()\n",
    "model_zoo_option=model_zoo_option_list[model_zoo_option_index]\n",
    "if model_zoo_option=='DEGIRUM_CLOUD_SERVER':\n",
    "    zoo = dg.connect_model_zoo(os.getenv('DEGIRUM_CLOUD_SERVER_ADDRESS'), token=os.getenv('DEGIRUM_CLOUD_TOKEN'))\n",
    "elif model_zoo_option=='P2P_VPN_SERVER':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('P2P_VPN_SERVER_ADDRESS'))\n",
    "elif model_zoo_option=='LOCAL_NETWORK_SERVER':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('LOCAL_NETWORK_SERVER_ADDRESS'))\n",
    "elif model_zoo_option=='LOCALHOST':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('LOCAL_HOST_ADDRESS'))\n",
    "else:\n",
    "    print('Model zoo option not supported \\n')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f4a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list all AI models available for inference\n",
    "zoo.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2baec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load AI model 'ssd_mobilenet_v2' for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "model = zoo.load_model(\"mobilenet_v2_ssd_coco--300x300_quant_n2x_orca_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27299231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure some result visualization parameters (optional step)\n",
    "model.image_backend = \"pil\" # use PIL as image rendering backend\n",
    "model.overlay_show_probabilities = True # show class probabilities on overlay image\n",
    "model.overlay_font_scale = 1.5 # increase font size for overlay image labels\n",
    "model.overlay_alpha = 1 # set minimum transparency for overlay image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03954556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform AI model inference on given image file (assuming current direcory is where this notebook is located)\n",
    "res = model(\"./images/TwoCats.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb207347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results of inference\n",
    "print(res) # numeric results\n",
    "res.image_overlay # graphical results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
