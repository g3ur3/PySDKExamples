{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08e7226",
   "metadata": {},
   "source": [
    "## This notebook is an example of how to pipeline two models. \n",
    "This notebook is an example how to use DeGirum PySDK to do AI inference of a graphical file using two AI models: person detection and pose detection. The person detection model is run on the image and the results are then processed by the pose detection model, one person bbox at a time.\n",
    "Combined result is then displayed.\n",
    "This script uses PIL as image processing backend.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you just need to uncomment **one** of the lines in the code below.\n",
    "\n",
    "You also need to specify your cloud API access token, cloud zoo URLs, and AI server hostname in [env.ini](env.ini) file, located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be62d11-d012-4d79-baca-15443054d0dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify where do you want to run your inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1e8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import degirum as dg, mytools\n",
    "\n",
    "#\n",
    "# Please UNCOMMENT only ONE of the following lines to specify where to run AI inference\n",
    "#\n",
    "\n",
    "target = dg.CLOUD # <-- on the Cloud Platform\n",
    "# target = mytools.get_ai_server_hostname() # <-- on AI Server deployed in your LAN\n",
    "# target = dg.LOCAL # <-- on ORCA accelerator installed on this computer\n",
    "\n",
    "# connect to AI inference engine getting zoo URL and token from env.ini file\n",
    "zoo = dg.connect(target, mytools.get_cloud_zoo_url(), mytools.get_token())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54615025-829b-4dd1-819c-2c755acbe3ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878db7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load models for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "people_det_model = zoo.load_model(\"yolo_v5s_person_det--512x512_quant_n2x_orca1_1\")\n",
    "pose_model = zoo.load_model(\"mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_orca1_1\")\n",
    "\n",
    "# adjust some model properties\n",
    "people_det_model.image_backend = \"pil\"\n",
    "pose_model.overlay_show_labels = False\n",
    "pose_model.overlay_line_width = 1\n",
    "pose_model.overlay_alpha = 1\n",
    "pose_model._model_parameters.PoseThreshold = 0.5\n",
    "pose_model.image_backend = \"pil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb81ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# detect persons\n",
    "people = people_det_model('./images/ThreePersons.jpg')\n",
    "\n",
    "# for each detected person detect poses\n",
    "with pose_model: # performance optimization to keep connection to pose_model open\n",
    "    for person in people.results:\n",
    "        person_box = people.image.crop(person['bbox'])\n",
    "        poses = pose_model(person_box)\n",
    "        display(poses.image_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e922940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alternatively, detect all poses\n",
    "all_poses = pose_model('./images/ThreePersons.jpg')\n",
    "display(all_poses.image_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04805154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
