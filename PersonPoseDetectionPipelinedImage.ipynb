{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08e7226",
   "metadata": {},
   "source": [
    "## This notebook is an example of how to pipeline two models. \n",
    "This notebook is an example how to use DeGirum PySDK to do AI inference of a graphical file using two AI models: person detection and pose detection. The person detection model is run on the image and the results are then processed by the pose detection model, one person bbox at a time.\n",
    "Combined result is then displayed.\n",
    "This script uses PIL as image processing backend.\n",
    "\n",
    "This script works with \n",
    "\n",
    "0. DeGirum Cloud Server, \n",
    "1. AI server equipped with DeGirum ORCA accelerator shared via Peer-to-Peer VPN, \n",
    "2. AI server equipped with DeGirum ORCA accelerator running in local network and \n",
    "3. AI server equipped with DeGirum ORCA accelerator running on the same machine as this code. \n",
    "\n",
    "To try different options, you just need to change the __model_zoo_option_index__ in the code below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b857e38-a500-4280-ba13-b8e5b14c48b3",
   "metadata": {},
   "source": [
    "### Specify your model zoo option here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo_option_list = ['DEGIRUM_CLOUD_SERVER', 'P2P_VPN_SERVER', 'LOCAL_NETWORK_SERVER', 'LOCALHOST']\n",
    "model_zoo_option_index=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cdc6b0-77f9-462c-9ba4-a0c9f0957939",
   "metadata": {},
   "source": [
    "### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f6e7d4-ab37-4836-992f-f1f8900b9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import cv2 # OpenCV\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "envs_loaded=load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082dca3f-a32f-4615-acd9-ae3b99f539c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo_option=model_zoo_option_list[model_zoo_option_index]\n",
    "if model_zoo_option=='DEGIRUM_CLOUD_SERVER':\n",
    "    zoo = dg.connect_model_zoo(os.getenv('DEGIRUM_CLOUD_SERVER_ADDRESS'), token=os.getenv('DEGIRUM_CLOUD_TOKEN'))\n",
    "elif model_zoo_option=='P2P_VPN_SERVER':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('P2P_VPN_SERVER_ADDRESS'))\n",
    "elif model_zoo_option=='LOCAL_NETWORK_SERVER':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('LOCAL_NETWORK_SERVER_ADDRESS'))\n",
    "elif model_zoo_option=='LOCALHOST':\n",
    "    zoo=dg.connect_model_zoo(os.getenv('LOCAL_HOST_ADDRESS'))\n",
    "else:\n",
    "    print('Model zoo option not supported \\n')                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878db7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "people_det_model = zoo.load_model(\"yolo_v5s_person_det--512x512_quant_n2x_orca_1\")\n",
    "pose_model = zoo.load_model(\"mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_orca_1\")\n",
    "\n",
    "# adjust some model properties\n",
    "pose_model.overlay_show_labels = False\n",
    "pose_model.overlay_line_width = 1\n",
    "pose_model.overlay_alpha = 1\n",
    "pose_model._model_parameters.PoseThreshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect persons\n",
    "people = people_det_model('./images/ThreePersons.jpg')\n",
    "\n",
    "# for each detected person detect poses\n",
    "for person in people.results:\n",
    "    person_box = people.image.crop(person['bbox'])\n",
    "    poses = pose_model(person_box)\n",
    "    display(poses.image_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e922940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively, detect all poses\n",
    "all_poses = pose_model('./images/ThreePersons.jpg')\n",
    "display(all_poses.image_overlay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
