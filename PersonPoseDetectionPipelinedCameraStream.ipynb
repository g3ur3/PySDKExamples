{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438aa03a",
   "metadata": {},
   "source": [
    "## This notebook is an example of how to pipeline two models. \n",
    "A video stream from a local camera is processed by the person detection model. The person detection results are then processed by the pose detection model, one person bounding box at a time.\n",
    "Combined result is then displayed.\n",
    "OpenCV is required to run this sample.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. [DeGirum Cloud Platform](https://cs.degirum.com),\n",
    "1. DeGirum-hosted AI server node shared via Peer-to-Peer VPN,\n",
    "1. AI server node hosted by you in your local network,\n",
    "1. AI server running on your local machine,\n",
    "1. DeGirum ORCA accelerator directly installed on your local machine.\n",
    "\n",
    "To try different options, you just need to change the `inference_option` in the code below.\n",
    "\n",
    "The script needs a web camera connected to the machine running this code. The `camera_index` also needs to be specified in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0f95d-7fd0-43b1-b94a-4835357d10a5",
   "metadata": {},
   "source": [
    "### Specify where do you want to run your inferences and camera index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b37dddf-3f5f-40b0-8bd9-409ae37bc7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_option = 1  # <<< change it according to your needs selecting from the list in the header comment\n",
    "camera_index = 0      # camera index; 0 is default camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68dc838-9d2b-4806-b48c-67912b4fdebe",
   "metadata": {},
   "source": [
    "### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d4cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import mytools, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983841ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference option = 'DeGirum Cloud Platform'\n"
     ]
    }
   ],
   "source": [
    "# connect to model zoo according to selected inference option\n",
    "zoo = mytools.connect_model_zoo(inference_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33012fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "people_det_model = zoo.load_model(\"yolo_v5s_person_det--512x512_quant_n2x_orca_1\")\n",
    "pose_model = zoo.load_model(\"mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_orca_1\")\n",
    "\n",
    "# adjust pose model properties\n",
    "pose_model.output_pose_threshold = 0.2 # lower threshold\n",
    "pose_model.overlay_line_width = 1\n",
    "pose_model.overlay_alpha = 1\n",
    "pose_model.overlay_show_probabilities = False\n",
    "pose_model.overlay_show_labels = False\n",
    "pose_model.image_backend = 'opencv' \n",
    "pose_model.input_numpy_colorspace = 'BGR'\n",
    "pose_model._model_parameters.InputImgFmt = ['JPEG']\n",
    "\n",
    "# adjust people model properties\n",
    "people_det_model.image_backend = 'opencv'\n",
    "people_det_model._model_parameters.InputImgFmt = ['JPEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8320e1c0-4c32-413b-bf47-78c699619a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened video stream\n"
     ]
    }
   ],
   "source": [
    "# open video stream from local camera \n",
    "stream = mytools.open_video_stream(camera_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93242ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI prediction loop\n",
    "# Press 'x' or 'q' to stop\n",
    "with mytools.Display(\"Poses\") as display:\n",
    "    \n",
    "    with pose_model: # performance optimization to keep connection to nested model open\n",
    "        \n",
    "        # run person detection model on a camera stream\n",
    "        for people in people_det_model.predict_batch(mytools.video_source(stream)):\n",
    "            # prepare list of bboxes of detected person\n",
    "            # if people is not None:\n",
    "            person_boxes = [person['bbox'] for person in people.results]\n",
    "            if not person_boxes:\n",
    "                continue\n",
    "\n",
    "            # prepare list of images cropped around each detected person\n",
    "            person_crops = [ mytools.Display.crop(people.image, box) for box in person_boxes ]\n",
    "\n",
    "            # for each detected person detect the pose\n",
    "            all_poses = None # accumulated result\n",
    "            for poses, box in zip(pose_model.predict_batch(person_crops), person_boxes):\n",
    "\n",
    "                for r in poses.results: # convert pose coordinates to back to original image\n",
    "                    for p in r['landmarks']:\n",
    "                        p['landmark'][0] += box[0]\n",
    "                        p['landmark'][1] += box[1]\n",
    "\n",
    "                if all_poses is None: # accumulate all detected poses\n",
    "                    all_poses = poses\n",
    "                    all_poses._input_image = people.image_overlay\n",
    "                else:\n",
    "                    all_poses._inference_results += poses.results\n",
    "\n",
    "            display.show(all_poses.image_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94b79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.release() # release camera stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15f39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
