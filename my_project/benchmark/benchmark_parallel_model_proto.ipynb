{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "#import os\n",
    "from pathlib import Path\n",
    "import gen_test_image_util as imgutil\n",
    "#import importlib\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "#import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "#importlib.reload(imgutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hw_location = \"@cloud\"\n",
    "hw_location = \"@local\"\n",
    "orca1_zoo_url = \"https://cs.degirum.com/degirum/public\"\n",
    "orca_zoo_url = \"https://cs.degirum.com/degirum/orca_models\"\n",
    "#model_zoo_url = \"https://cs.degirum.com/degirum/ultralytics_v6\"\n",
    "device_family = \"ORCA1\"  # models of which device family to use\n",
    "exclude_preprocessing = True\n",
    "use_jpeg = True\n",
    "\n",
    "image_dir = Path('/home/gotom/data_dir/split_pic')\n",
    "\n",
    "num_of_pics = 200\n",
    "#max_count = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************************************************************************\n",
    "# multi_model_parallel_test()\n",
    "#*******************************************************************************************************\n",
    "def multi_models_parallel_test(model_names, model_instances, image_file,\\\n",
    "                                exclude_preprocessing, iterations, batch):\n",
    "    ret = {}\n",
    "    data = []   \n",
    "    nmodels = len(model_instances)\n",
    "    for mi, model_name in enumerate(model_names):\n",
    "        ret[model_name] = {}\n",
    "        frame = image_file\n",
    "        if exclude_preprocessing:\n",
    "            frame = model_instances[mi]._preprocessor.forward(frame)[0]\n",
    "        data.append(frame)\n",
    "    # define source of frames\n",
    "    def source(mi):\n",
    "        for fi in range(iterations):\n",
    "            yield data[mi]  \n",
    "    barr = threading.Barrier(nmodels)\n",
    "\n",
    "    def run_one_model(mi):\n",
    "        with model_instances[mi] as model:\n",
    "            model.eager_batch_size = batch\n",
    "            model.frame_queue_depth = batch\n",
    "            model(data[mi])  # run model once to warm up the system\n",
    "            model.reset_time_stats()\n",
    "            barr.wait()\n",
    "            t = dgtools.Timer()          \n",
    "            for res in model.predict_batch(source(mi,)):\n",
    "                pass\n",
    "            ret[model_names[mi]] = {\n",
    "                    \"elapsed\": t(),\n",
    "                    \"time_stats\": model.time_stats(),\n",
    "                }\n",
    "    threads = [\n",
    "            threading.Thread(target=run_one_model, args=(mi,)) for mi in range(nmodels)\n",
    "        ]\n",
    "    [thread.start() for thread in threads]\n",
    "    [thread.join() for thread in threads]\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************************************************************************\n",
    "# multi_model_parallel_test2()\n",
    "#*******************************************************************************************************\n",
    "def multi_models_parallel_test(model_names, model_instances, image_file,\\\n",
    "                                exclude_preprocessing, iterations, batch):\n",
    "    ret = {}\n",
    "    data = []   \n",
    "    nmodels = len(model_instances)\n",
    "    for mi, model_name in enumerate(model_names):\n",
    "        ret[model_name] = {}\n",
    "        frame = image_file\n",
    "        if exclude_preprocessing:\n",
    "            frame = model_instances[mi]._preprocessor.forward(frame)[0]\n",
    "        data.append(frame)\n",
    "    # define source of frames\n",
    "    # def source(mi):\n",
    "    #     for fi in range(iterations):\n",
    "    #         yield data[mi]  \n",
    "    # barr = threading.Barrier(nmodels)\n",
    "\n",
    "    # def run_one_model(mi):\n",
    "    #     with model_instances[mi] as model:\n",
    "    #         model.eager_batch_size = batch\n",
    "    #         model.frame_queue_depth = batch\n",
    "    #         model(data[mi])  # run model once to warm up the system\n",
    "    #         model.reset_time_stats()\n",
    "    #         barr.wait()\n",
    "            t = dgtools.Timer()          \n",
    "    #         for res in model.predict_batch(source(mi,)):\n",
    "    #             pass\n",
    "    #         ret[model_names[mi]] = {\n",
    "    #                 \"elapsed\": t(),\n",
    "    #                 \"time_stats\": model.time_stats(),\n",
    "    #             }\n",
    "    # threads = [\n",
    "    #         threading.Thread(target=run_one_model, args=(mi,)) for mi in range(nmodels)\n",
    "    #     ]\n",
    "    # [thread.start() for thread in threads]\n",
    "    # [thread.join() for thread in threads]\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_transaction(model_instance, image_chunk_pathL, iterations):\n",
    "    \n",
    "    count = 0\n",
    "    #print(f'start_index:{start_index}')\n",
    "    try:\n",
    "        for res in model_instance.predict_batch(imgutil.pics_transaction_gen(model_instance, image_chunk_pathL[:iterations], exclude_preprocessing, iterations)):\n",
    "            count += 1\n",
    "            #pass\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    #print(f'count:{count}')\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [224, 224, 200]\n",
    "      \n",
    "mobile_net_v1_durationD = {}\n",
    "mobile_net_v2_durationD = {}\n",
    "\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgutil.remove_image_chunk(image_dir, 3000)\n",
    "image_chunkL = imgutil.create_test_image_chunk('maami_1.jpg', image_size)\n",
    "image_chunk_pathL = imgutil.save_image_chunk(image_dir, image_chunkL)\n",
    "    \n",
    "orca_zoo = dg.connect(hw_location, orca_zoo_url, degirum_tools.get_token()) # connect to AI inference engine\n",
    "orca1_zoo = dg.connect(hw_location, orca1_zoo_url, degirum_tools.get_token()) # connect to AI inference engine\n",
    "\n",
    "#model_orca = 'mobilenet_v1_imagenet--224x224_quant_n2x_orca_1'\n",
    "#model_orca1 = 'mobilenet_v1_imagenet--224x224_quant_n2x_orca1_1'   \n",
    "model_orca = 'mobilenet_v2_imagenet--224x224_quant_n2x_orca_1'\n",
    "model_orca1 = 'mobilenet_v2_imagenet--224x224_quant_n2x_orca1_1'   \n",
    "exclude_preprocessing = True\n",
    "\n",
    "durationL = []\n",
    "          \n",
    "image = cv2.imread(image_chunk_pathL[0], cv2.IMREAD_COLOR)\n",
    "h,w = image.shape[:2]\n",
    "image_size[0] = h\n",
    "image_size[1] = w\n",
    "\n",
    "instance_orca = imgutil.create_model_instances(model_orca, orca_zoo, batch_size, use_jpeg)\n",
    "instance_orca1 = imgutil.create_model_instances(model_orca1, orca1_zoo, batch_size, use_jpeg)\n",
    "#instance_orca = instance_orca[0]\n",
    "#instance_orca1 = instance_orca1[0]\n",
    "\n",
    "instance_orca(image_chunk_pathL[0]) #dummy\n",
    "instance_orca1(image_chunk_pathL[100]) #dummy\n",
    "\n",
    "instance_orca.reset_time_stats()\n",
    "instance_orca1.reset_time_stats()\n",
    "\n",
    "count = 0\n",
    "countL = []\n",
    "resultL = []\n",
    "        \n",
    "#single device orca\n",
    "t = degirum_tools.Timer()\n",
    "count = partial_transaction(instance_orca, image_chunk_pathL, 0, 200)\n",
    "orca_elapsed_time = round(1e3*t(),1)\n",
    "#print(f'count = {count}')  \n",
    "#print(f'mobile_net_v1_duration (ORCA single device): {elapsed_time}msec')\n",
    "\n",
    "#single device orca1\n",
    "t = degirum_tools.Timer()\n",
    "count = partial_transaction(instance_orca1, image_chunk_pathL, 0, 200)\n",
    "orca1_elapsed_time = round(1e3*t(),1)\n",
    "#print(f'count = {count}') \n",
    "#print(f'mobile_net_v1_duration (ORCA1 single device): {elapsed_time}msec')\n",
    "\n",
    "#two devices orca + orca1\n",
    "t = degirum_tools.Timer()\n",
    "with ThreadPoolExecutor(max_workers = 2) as exctor:\n",
    "    count_orca = exctor.submit(partial_transaction, instance_orca, image_chunk_pathL, 0, 100)\n",
    "    count_orca1 = exctor.submit(partial_transaction, instance_orca1, image_chunk_pathL, 100, 100) \n",
    "    \n",
    "    #print(f'countL:{countL}')\n",
    "    resultL = [count_orca.result(), count_orca1.result()]   \n",
    "    #print(f'resultL = {resultL}')              \n",
    "    two_orca_elapsed_time = round(1e3*t(),1)  \n",
    "    #print(f'count:{sum(resultL)}')\n",
    "    if not(sum(resultL) == num_of_pics): \n",
    "        exit()\n",
    "    \n",
    "    #height_width = str(h) + 'x' + str(w)\n",
    "    #mobile_net_v1_durationD[height_width] = elapsed_time\n",
    "    #mobile_net_v2_durationD[height_width] = elapsed_time\n",
    "            \n",
    "#print(f'mobile_net_v1_duration (ORCA + ORCA1): {elapsed_time}msec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 images transaction demo (Single device, Two devices)\n",
      "\n",
      "hw_location:  @local\n",
      "Batch Size:   16\n",
      "Image Size:   224 x 224\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "| Model name                                        | Device              | 200 Images Inference Time[ms] |\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "| mobilenet_v2_imagenet--224x224_quant_n2x_orca_1   | ORCA                |                          947.2|\n",
      "| mobilenet_v2_imagenet--224x224_quant_n2x_orca1_1  | ORCA1               |                          614.6|\n",
      "| mobilenet_v2_imagenet--224x224_quant_n2x_orca1_1  | ORCA + ORCA1        |                          485.5|\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print results    \n",
    "CW = (50, 20, 30)  # column widths\n",
    "header = f\"| {'Model name':{CW[0]}}| {'Device':{CW[1]}}| {'200 Images Inference Time[ms]':{CW[2]}}|\"\n",
    "\n",
    "print('200 images transaction demo (Single device, Two devices)\\n')\n",
    "print(f\"hw_location:  {hw_location}\")\n",
    "print(f\"Batch Size:   16\")\n",
    "print(f'Image Size:   224 x 224')\n",
    "print(f\"{'-'*len(header)}\")\n",
    "print(header)\n",
    "print(f\"{'-'*len(header)}\")\n",
    "\n",
    "print(f\"| {model_orca:{CW[0]}}|\" + f\"{' ORCA':{CW[1]}} |\" + f\" {orca_elapsed_time:{CW[2]}}|\")\n",
    "print(f\"| {model_orca1:{CW[0]}}|\" + f\"{' ORCA1':{CW[1]}} |\" + f\" {orca1_elapsed_time:{CW[2]}}|\")\n",
    "print(f\"| {model_orca1:{CW[0]}}|\" + f\"{' ORCA + ORCA1':{CW[1]}} |\" + f\" {two_orca_elapsed_time:{CW[2]}}|\")  \n",
    "    \n",
    "print(f\"{'-'*len(header)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "degirum_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
