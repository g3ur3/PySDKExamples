{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gen_test_image_util as imgutil\n",
    "#import importlib\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "#importlib.reload(imgutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_location = \"@cloud\"\n",
    "#hw_location = \"@local\"\n",
    "#model_zoo_url = \"https://cs.degirum.com/degirum/public\"\n",
    "model_zoo_url = \"https://cs.degirum.com/degirum/ultralytics_v6\"\n",
    "#device_family = \"ORCA1\"  # models of which device family to use\n",
    "device_family = \"EDGETPU\"\n",
    "image_dir = Path('/home/gotom/data_dir/split_pic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:224x224\n",
      "726\n"
     ]
    }
   ],
   "source": [
    "#create image chunk \n",
    "image_sizeL = [224, 224, 200]\n",
    "image_chunkL = imgutil.create_test_image_chunk('maami_1.jpg', image_sizeL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image chunk\n",
    "image_chunks_pathL = imgutil.save_image_chunk(image_dir, image_chunkL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_instances(model_name, zoo, batch_size, use_jpeg):\n",
    "\n",
    "    model_instance = zoo.load_model(model_name)\n",
    "    model_instance.image_backend = \"pil\"  # select OpenCV backend\n",
    "    model_instance.input_numpy_colorspace = \"RGB\"      \n",
    "    model_instance._model_parameters.InputImgFmt = [\"JPEG\" if use_jpeg else \"RAW\"]\n",
    "    model_instance.measure_time = True\n",
    "    model_instance.eager_batch_size = batch_size\n",
    "    model_instance.frame_queue_depth = batch_size\n",
    "\n",
    "    return model_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(target_modelsL, batch_size, image_sizeL, durationL, observed_fpsL, expected_fpsL):\n",
    "    \n",
    "    CW = (65,30, 16, 16)  # column widths\n",
    "    header = f\"| {'Model name':{CW[0]}}| {f'{image_sizeL[2]} Images Inference Time[ms]':{CW[1]}} | {'Observed FPS':{CW[2]}} | {'Max Possible FPS':{CW[3]}} |\"\n",
    "\n",
    "    print(f\"hw_location:  {hw_location}\")\n",
    "    print(f\"model_zoo_url:{model_zoo_url}\")\n",
    "    print(f'Batch Size:   {batch_size}')\n",
    "    print(f'Image Size:   {image_sizeL[0]} x {image_sizeL[1]}')\n",
    "    print(f\"{'-'*len(header)}\")\n",
    "    print(header)\n",
    "    print(f\"{'-'*len(header)}\")\n",
    "\n",
    "    for mi, model in enumerate(target_modelsL):\n",
    "        print(f\"| {target_modelsL[mi]:{CW[0]}}|\" + f\" {durationL[mi]:{CW[1]}} |\" + f\" {observed_fpsL[mi]:{CW[2]}} |\" + f\" {expected_fpsL[mi]:{CW[3]}} |\")\n",
    "    \n",
    "    print(f\"{'-'*len(header)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "def save_results(target_modelsL, batch_size, image_sizeL, durationL, observed_fpsL, expected_fpsL):\n",
    "    CW = (65,30, 16, 16)  # column widths\n",
    "    header = f\"| {'Model name':{CW[0]}}| {f'{image_sizeL[2]} Images Inference Time[ms]':{CW[1]}} | {'Observed FPS':{CW[2]}} | {'Max Possible FPS':{CW[3]}} |\"\n",
    "\n",
    "    d = time.strftime('%m%d%H%M')\n",
    "    data_dir = '/home/gotom/data_dir/200pics_measure/' \n",
    "    file = data_dir + 'test_results' + d + '.txt'\n",
    "\n",
    "    f = open(file, 'w')\n",
    "    f.write(f\"hw_location:  {hw_location}\\n\")\n",
    "    f.write(f\"model_zoo_url:{model_zoo_url}\\n\")\n",
    "    f.write(f'Batch Size:   {batch_size}\\n')\n",
    "    f.write(f'Image Size:   {image_sizeL[0]} x {image_sizeL[1]}\\n')\n",
    "    f.write(f\"{'-'*len(header)}\\n\")\n",
    "    f.write(header + '\\n')\n",
    "    f.write(f\"{'-'*len(header)}\\n\")\n",
    "\n",
    "    for mi, model in enumerate(target_modelsL):\n",
    "    \n",
    "        f.write(f\"| {target_modelsL[mi]:{CW[0]}}|\" + f\" {durationL[mi]:{CW[1]}} |\" + f\" {observed_fpsL[mi]:{CW[2]}} |\" + f\" {expected_fpsL[mi]:{CW[3]}} |\\n\")\n",
    "    \n",
    "    f.write(f\"{'-'*len(header)}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mame: yolov5nu_silu_coco--640x640_quant_tflite_edgetpu_1\n",
      "mame: yolov5su_silu_coco--640x640_quant_tflite_edgetpu_1\n",
      "mame: yolov8n_silu_coco--640x640_quant_tflite_edgetpu_1\n",
      "mame: yolov8s_silu_coco--640x640_quant_tflite_edgetpu_1\n"
     ]
    }
   ],
   "source": [
    "zoo = dg.connect(hw_location, model_zoo_url, degirum_tools.get_token()) # connect to AI inference engine\n",
    "model_name = zoo.list_models(device=device_family)\n",
    "\n",
    "#target_modelsL = ['mobilenet_v1_imagenet--224x224_quant_n2x_orca1_1', 'mobilenet_v2_imagenet--224x224_quant_n2x_orca1_1']\n",
    "\n",
    "target_modelsL = []\n",
    "\n",
    "#target_modelsL = model_name\n",
    "\n",
    "for name in model_name:\n",
    "\n",
    "    if not name.find('coco') == -1:\n",
    "        #print(f'mame: {name}')\n",
    "        target_modelsL.append(name)\n",
    "               \n",
    "for name in target_modelsL:\n",
    "    \n",
    "    if name.find('sound') > 0:\n",
    "        #print(f'mame: {name}')\n",
    "        target_modelsL.remove(name)\n",
    "        \n",
    "    elif name.find('silu') > 0:\n",
    "        print(f'mame: {name}')\n",
    "        target_modelsL.remove(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gotom/data_dir/split_pic/chunk_199.jpg\n"
     ]
    }
   ],
   "source": [
    "#get image chunk\n",
    "image_dir = Path('/home/gotom/data_dir/split_pic/')\n",
    "image_chunk_pathL = imgutil.get_image_chunk_path(image_dir, image_sizeL[2])\n",
    "print(image_chunk_pathL[image_sizeL[2] -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: yolov5nu_relu6_coco--640x640_quant_tflite_edgetpu_1\n",
      "image_size; 224 x 224\n",
      "count = 200\n",
      "model_name: yolov5su_relu6_coco--640x640_quant_tflite_edgetpu_1\n",
      "image_size; 224 x 224\n",
      "count = 200\n",
      "model_name: yolov8n_relu6_coco--640x640_quant_tflite_edgetpu_1\n",
      "image_size; 224 x 224\n",
      "count = 200\n",
      "model_name: yolov8s_relu6_coco--640x640_quant_tflite_edgetpu_1\n",
      "image_size; 224 x 224\n",
      "count = 200\n"
     ]
    }
   ],
   "source": [
    "exclude_preprocessing = True\n",
    "use_jpeg = True\n",
    "\n",
    "batch_sizeL = [2, 4, 8, 16]\n",
    "\n",
    "durationL = []\n",
    "observed_fpsL = []\n",
    "expected_fpsL = []\n",
    "\n",
    "batch_size = batch_sizeL[3]\n",
    "for mi, model_name in enumerate(target_modelsL):\n",
    "    print(f'model_name: {model_name}')\n",
    "    model_instance = create_model_instances(model_name, zoo, batch_size, use_jpeg) \n",
    "    \n",
    "    image = cv2.imread(image_chunk_pathL[0], cv2.IMREAD_COLOR)\n",
    "    h,w = image.shape[:2]\n",
    "    image_sizeL[0] = h\n",
    "    image_sizeL[1] = w\n",
    "    \n",
    "    print(f'image_size; {image_sizeL[0]} x {image_sizeL[1]}')\n",
    "    #print(str(image_chunks_pathL[0]))  \n",
    "    model_instance(image_chunk_pathL[0]) #dummy\n",
    "\n",
    "    model_instance.reset_time_stats()\n",
    "\n",
    "    count = 0\n",
    "    t = degirum_tools.Timer()\n",
    "    \n",
    "    for res in model_instance.predict_batch(imgutil.pics_transaction_gen(model_instance, image_chunk_pathL, exclude_preprocessing, image_sizeL[2])):\n",
    "        count += 1\n",
    "        #pass\n",
    "\n",
    "    print(f'count = {count}')\n",
    "    \n",
    "    if not(count == image_sizeL[2]): \n",
    "       exit()\n",
    "     \n",
    "    elapsed_time = round(1e3*t(),1)   \n",
    "    durationL.append(elapsed_time)\n",
    "    \n",
    "    time_stats = model_instance.time_stats()\n",
    "    inference_ms = time_stats[\"CoreInferenceDuration_ms\"].avg\n",
    "    frame_duration_ms = elapsed_time / image_sizeL[2]\n",
    "    observed_fps_value = round(1e3 / frame_duration_ms, 1) \n",
    "    expected_fps_value = round(1e3 / inference_ms, 1)\n",
    "    \n",
    "    observed_fpsL.append(observed_fps_value)\n",
    "    expected_fpsL.append(expected_fps_value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw_location:  @cloud\n",
      "model_zoo_url:https://cs.degirum.com/degirum/ultralytics_v6\n",
      "Batch Size:   16\n",
      "Image Size:   224 x 224\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| Model name                                                       | 200 Images Inference Time[ms]  | Observed FPS     | Max Possible FPS |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| yolov5nu_relu6_coco--640x640_quant_tflite_edgetpu_1              |                       476997.5 |              0.4 |              0.4 |\n",
      "| yolov5su_relu6_coco--640x640_quant_tflite_edgetpu_1              |                      1298633.7 |              0.2 |              0.2 |\n",
      "| yolov8n_relu6_coco--640x640_quant_tflite_edgetpu_1               |                       542933.4 |              0.4 |              0.4 |\n",
      "| yolov8s_relu6_coco--640x640_quant_tflite_edgetpu_1               |                      1554712.9 |              0.1 |              0.1 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_results(target_modelsL, batch_size, image_sizeL, durationL, observed_fpsL, expected_fpsL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(target_modelsL, batch_size, image_sizeL, durationL, observed_fpsL, expected_fpsL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "degirum_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
