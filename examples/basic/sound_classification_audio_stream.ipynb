{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f257328f",
   "metadata": {},
   "source": [
    "## Example script illustrating sound classification on audio stream\n",
    "This notebook is an example how to use DeGirum PySDK to do sound classification AI inference of an audio stream from local microphone.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you just need to uncomment **one** of the lines in the code below.\n",
    "\n",
    "You also need to specify your cloud API access token, cloud zoo URLs, and AI server hostname in [env.ini](../../env.ini) file, located in the same directory as this notebook.\n",
    "\n",
    "**pyaudio package with portaudio is required to run this sample.**\n",
    "\n",
    "The script may use local microphone connected to the machine running this code. Alternatively, you may use the WAV file.\n",
    "The mic index or WAV filename needs to be specified either in the code below by assigning `audio_source` or in [env.ini](../../env.ini) file by defining `AUDIO_SOURCE` variable \n",
    "and assigning `audio_source = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package is installed\n",
    "!pip show degirum-tools || pip install degirum-tools\n",
    "\n",
    "# to install pyaudio package, uncomment the following lines\n",
    "#!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
    "#!pip show pyaudio || pip install pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify audio id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_source = None          # mic index or WAV file name; 0 to use default mic, None to take from env.ini file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227c649-6c23-41d1-a6df-4247f4a6a480",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify where do you want to run your inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef133f4-8197-4de5-a44e-c76dbbd39a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "\n",
    "degirum_tools.configure_colab() # configure for Google Colab\n",
    "\n",
    "#\n",
    "# Please UNCOMMENT only ONE of the following lines to specify where to run AI inference\n",
    "#\n",
    "\n",
    "target = dg.CLOUD # <-- on the Cloud Platform\n",
    "# target = degirum_tools.get_ai_server_hostname() # <-- on AI Server deployed in your LAN\n",
    "# target = dg.LOCAL # <-- on ORCA accelerator installed on this computer\n",
    "\n",
    "# connect to AI inference engine getting zoo URL and token from env.ini file\n",
    "zoo = dg.connect(target, degirum_tools.get_cloud_zoo_url(), degirum_tools.get_token())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86162da-d4bc-42d6-b839-b10025306796",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a1753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd775c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load YAMNET sound classification model for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "model = zoo.load_model(\"mobilenet_v1_yamnet_sound_cls--96x64_quant_n2x_orca1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db989e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abort = False  # stream abort flag\n",
    "N = 5  # inference results history depth\n",
    "history = []  # list of N consecutive inference results\n",
    "\n",
    "sampling_rate_hz = model.model_info.InputSamplingRate[0]\n",
    "read_buf_size = model.model_info.InputWaveformSize[0] // 2  # to have 50% overlap\n",
    "\n",
    "# Acquire model input stream object\n",
    "with degirum_tools.open_audio_stream(sampling_rate_hz, read_buf_size, audio_source) as stream:\n",
    "    #\n",
    "    # AI prediction loop.\n",
    "    # emit keyboard typing sound to stop\n",
    "    #\n",
    "    for res in model.predict_batch(\n",
    "        degirum_tools.audio_overlapped_source(stream, lambda: abort)\n",
    "    ):\n",
    "        # add top inference result to history\n",
    "        history.insert(0, f\"{res.results[0]['label']}: {res.results[0]['score']}\")\n",
    "        if len(history) > N:  # keep only N last elements in history\n",
    "            history.pop()\n",
    "\n",
    "        clear_output(wait=True)  # clear Jupyter output cell\n",
    "        for m in history:  # print history\n",
    "            print(m)\n",
    "\n",
    "        if res.results[0][\"label\"] == \"Typing\":  # check for stop condition\n",
    "            abort = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63eee6-e66d-4a23-bce6-1d4bcf41cce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
