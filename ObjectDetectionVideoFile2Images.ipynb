{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c15cb24",
   "metadata": {},
   "source": [
    "## AI Inference from a video file into a bunch of images\n",
    "This notebook is an example how to use DeGirum PySDK to do AI inference of a video stream from a video file. The annotated frames are saved into new directory with `_annotated` suffix.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. [DeGirum Cloud Platform](https://cs.degirum.com),\n",
    "1. DeGirum-hosted AI server node shared via Peer-to-Peer VPN,\n",
    "1. AI server node hosted by you in your local network,\n",
    "1. AI server running on your local machine,\n",
    "1. DeGirum ORCA accelerator directly installed on your local machine.\n",
    "\n",
    "To try different options, you just need to change the `inference_option` in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01549d7c-2445-4007-8a89-ac0f3a864530",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specify where do you want to run your inferences and video file name here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34df11-cbc7-4b00-8994-794a4a6548b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_option = 1  # <<< change it according to your needs selecting from the list in the header comment\n",
    "input_filename = \"./images/Traffic.mp4\" # video file to process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4549b06-567f-4cdb-8b82-bb4ef5858f2f",
   "metadata": {},
   "source": [
    "### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import mytools, cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to model zoo according to selected inference option\n",
    "zoo = mytools.connect_model_zoo(inference_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load object detection model\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "model = zoo.load_model(\"mobilenet_v2_ssd_coco--300x300_quant_n2x_orca_1\")\n",
    "\n",
    "# set model parameters\n",
    "model.image_backend = 'opencv' # select OpenCV backend: needed to have overlay image in OpenCV format\n",
    "model.input_numpy_colorspace = 'BGR'\n",
    "model.overlay_show_probabilities = True # show probabilities on overlay image\n",
    "model.overlay_line_width = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_path = Path(input_filename)\n",
    "frame_path = orig_path.parent / (orig_path.name + \"_original\") # construct original images directory path\n",
    "\n",
    "# decode video stream into a set of jpeg images\n",
    "nframes = mytools.video2jpegs(input_filename, frame_path)\n",
    "print(f\"{nframes} images are saved into '{frame_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8906309-0ea3-458f-a1c4-282b2de56a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path = orig_path.parent / (orig_path.name + \"_annotated\") # construct annotated images directory path\n",
    "\n",
    "if not ann_path.exists(): # create directory for annotated images\n",
    "    ann_path.mkdir()\n",
    "    \n",
    "# AI prediction loop\n",
    "fi = 0 # frame index\n",
    "print(\"Processing frames:\")\n",
    "progress = mytools.Progress(nframes)\n",
    "for res in model.predict_dir(str(frame_path)):\n",
    "    fname = str(ann_path / f\"frame_{fi:05d}.jpg\")\n",
    "    cv2.imwrite(fname, res.image_overlay)\n",
    "    fi += 1\n",
    "    progress.step()\n",
    "print(f\"{nframes} annotated images are saved into '{ann_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c38ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
