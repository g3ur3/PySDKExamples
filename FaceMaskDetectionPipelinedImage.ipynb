{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08e7226",
   "metadata": {},
   "source": [
    "## This notebook is an example of how to pipeline two models. \n",
    "This notebook is an example how to use DeGirum PySDK to do AI inference of a graphical file using two AI models: face detection and mask detection. The face detection model is run on the image and the results are then processed by the mask detection model, one face bbox at a time.\n",
    "Combined result is then displayed.\n",
    "This script uses PIL as image processing backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f6e7d4-ab37-4836-992f-f1f8900b9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import mytools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449aafef",
   "metadata": {},
   "source": [
    "### Specify inference option here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082dca3f-a32f-4615-acd9-ae3b99f539c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment and edit one of the following inference options to specify your system configuration case according to\n",
    "# https://cs.degirum.com/doc/0.5.0/degirum.html#system-configuration-for-specific-use-cases\n",
    "\n",
    "# 1. DeGirum Cloud Zoo inference:\n",
    "#zoo = dg.connect_model_zoo(\"dgcps://cs.degirum.com\", token=mytools.token_get())\n",
    "\n",
    "# 2. AIServer inference via IP address using models from DeGirum Cloud model zoo\n",
    "#zoo = dg.connect_model_zoo((\"192.168.0.7\", \"https://cs.degirum.com/degirum_com/public\"), token=mytools.token_get())\n",
    "\n",
    "# 3. AIServer inference via IP address using local model zoo\n",
    "#zoo = dg.connect_model_zoo(\"192.168.0.1\")\n",
    "\n",
    "# 4. ORCA board installed locally using models from DeGirum Cloud Model Zoo\n",
    "#zoo = dg.connect_model_zoo(\"https://cs.degirum.com/degirum_com/public\", token=mytools.token_get())\n",
    "\n",
    "# 5. Local inference with locally deployed model\n",
    "#zoo = dg.connect_model_zoo(\"full/path/to/model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878db7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "face_det_model = zoo.load_model(\"yolo_v5s_face_det--512x512_quant_n2x_orca_1\")\n",
    "mask_det_model = zoo.load_model(\"mobilenet_v2_mask_yn_cls--224x224_float_n2x_orca_1\")\n",
    "\n",
    "# adjust some model properties\n",
    "face_det_model.output_confidence_threshold = 0.7\n",
    "face_det_model.overlay_font_scale = 1.5\n",
    "face_det_model.overlay_alpha = 1\n",
    "mask_det_model.overlay_show_labels = True\n",
    "mask_det_model.overlay_font_scale = 1.5\n",
    "mask_det_model.overlay_alpha = 1\n",
    "mask_det_model.output_top_k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect persons\n",
    "faces = face_det_model('./images/Mask1.jpg')\n",
    "\n",
    "# for each detected face detect mask\n",
    "with mask_det_model: # performance optimization to keep connection to mask_det_model open\n",
    "    for face in faces.results:\n",
    "        face_box = faces.image.crop(face['bbox'])\n",
    "        mask = mask_det_model(face_box)\n",
    "        face[\"label\"] = mask.results[0][\"label\"]\n",
    "        display(mask.image_overlay)\n",
    "\n",
    "# display combined results\n",
    "display(faces.image_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eee6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f77ba0ef977241afac66801d7297b5fb2ffa6cc21668a24d017a9f23b5f689e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
