{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08e7226",
   "metadata": {},
   "source": [
    "## This notebook is an example of how to pipeline two models. \n",
    "This notebook is an example how to use DeGirum PySDK to do AI inference of a graphical file using two AI models: face detection and mask detection. The face detection model is run on the image and the results are then processed by the mask detection model, one face bbox at a time.\n",
    "Combined result is then displayed.\n",
    "This script uses PIL as image processing backend.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you just need to uncomment **one** of the lines in the code below.\n",
    "\n",
    "You also need to specify your cloud API access token, cloud zoo URLs, and AI server hostname in [env.ini](env.ini) file, located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960afca-3c84-4794-a8d0-ae894260f40b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify where do you want to run your inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01889e8e-c81a-4514-a16e-bb13652e61e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import degirum as dg, mytools\n",
    "\n",
    "cloud_token = mytools.get_token() # get cloud API access token from env.ini file\n",
    "cloud_zoo_url = mytools.get_cloud_zoo_url() # get cloud zoo URL from env.ini file\n",
    "\n",
    "#\n",
    "# Please UNCOMMENT only ONE of the following lines to specify where to run AI inference\n",
    "#\n",
    "\n",
    "# 1. Inference on the DeGirum Cloud Platform\n",
    "zoo = dg.connect(dg.CLOUD, cloud_zoo_url, cloud_token)\n",
    "\n",
    "# 2. Inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN\n",
    "# zoo = dg.connect(mytools.get_ai_server_hostname(), cloud_zoo_url, cloud_token)\n",
    "\n",
    "# 3. Inference on DeGirum ORCA accelerator installed on your computer\n",
    "# zoo = dg.connect(dg.LOCAL, cloud_zoo_url, cloud_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d2ce9-610e-4727-a18d-f0467b326d7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878db7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load models for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "face_det_model = zoo.load_model(\"yolo_v5s_face_det--512x512_quant_n2x_orca_1\")\n",
    "mask_det_model = zoo.load_model(\"mobilenet_v2_mask_yn_cls--224x224_float_n2x_orca_1\")\n",
    "\n",
    "# adjust some model properties\n",
    "face_det_model.output_confidence_threshold = 0.7\n",
    "face_det_model.overlay_font_scale = 1.5\n",
    "face_det_model.overlay_alpha = 1\n",
    "mask_det_model.overlay_show_labels = True\n",
    "mask_det_model.overlay_font_scale = 1.5\n",
    "mask_det_model.overlay_alpha = 1\n",
    "mask_det_model.output_top_k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb81ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# detect persons\n",
    "faces = face_det_model('./images/Mask1.jpg')\n",
    "\n",
    "# for each detected face detect mask\n",
    "with mask_det_model: # performance optimization to keep connection to mask_det_model open\n",
    "    for face in faces.results:\n",
    "        face_box = faces.image.crop(face['bbox'])\n",
    "        mask = mask_det_model(face_box)\n",
    "        face[\"label\"] = mask.results[0][\"label\"]\n",
    "        display(mask.image_overlay)\n",
    "\n",
    "# display combined results\n",
    "display(faces.image_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eee6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f77ba0ef977241afac66801d7297b5fb2ffa6cc21668a24d017a9f23b5f689e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
