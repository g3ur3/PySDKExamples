{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438aa03a",
   "metadata": {},
   "source": [
    "## This notebook is an example of how to pipeline two models. \n",
    "A video stream from a local camera is processed by the face detection model. The face detection results are then processed by the mask detection model, one face bounding box at a time.\n",
    "Combined result is then displayed.\n",
    "\n",
    "**Access to camera is required to run this sample.**\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. [DeGirum Cloud Platform](https://cs.degirum.com),\n",
    "1. DeGirum-hosted AI server node shared via Peer-to-Peer VPN,\n",
    "1. AI server node hosted by you in your local network,\n",
    "1. AI server running on your local machine,\n",
    "1. DeGirum ORCA accelerator directly installed on your local machine.\n",
    "\n",
    "To try different options, you just need to change the `inference_option` in the code below.\n",
    "\n",
    "The script needs either a web camera or local camera connected to the machine running this code. The camera index or URL needs to be specified either in the code below by assigning `camera_id` or in .env file by defining `CAMERA_ID` variable and assigning `camera_id = None`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0f95d-7fd0-43b1-b94a-4835357d10a5",
   "metadata": {},
   "source": [
    "### Specify where do you want to run your inferences and camera index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37dddf-3f5f-40b0-8bd9-409ae37bc7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_option = 1  # <<< change it according to your needs selecting from the list in the header comment\n",
    "camera_id = 0         # camera index or URL; 0 to use default local camera, None to take from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68dc838-9d2b-4806-b48c-67912b4fdebe",
   "metadata": {},
   "source": [
    "### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import mytools, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983841ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to model zoo according to selected inference option\n",
    "zoo = mytools.connect_model_zoo(inference_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33012fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "face_det_model = zoo.load_model(\"yolo_v5s_face_det--512x512_quant_n2x_orca_1\")\n",
    "mask_det_model = zoo.load_model(\"mobilenet_v2_mask_yn_cls--224x224_float_n2x_orca_1\")\n",
    "\n",
    "# adjust mask model properties\n",
    "mask_det_model.output_top_k = 1 # report single result with top confidence\n",
    "mask_det_model.image_backend = 'opencv' \n",
    "mask_det_model.input_numpy_colorspace = 'BGR'\n",
    "mask_det_model._model_parameters.InputImgFmt = ['JPEG']\n",
    "\n",
    "# adjust face model properties\n",
    "face_det_model.output_confidence_threshold = 0.7\n",
    "face_det_model.overlay_font_scale = 1.5\n",
    "face_det_model.overlay_alpha = 1\n",
    "face_det_model.image_backend = 'opencv'\n",
    "face_det_model._model_parameters.InputImgFmt = ['JPEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93242ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI prediction loop\n",
    "# Press 'x' or 'q' to stop\n",
    "with mytools.Display(\"Faces\") as display, \\\n",
    "     mytools.open_video_stream(camera_id) as stream:\n",
    "    \n",
    "    with mask_det_model: # performance optimization to keep connection to nested model open\n",
    "        \n",
    "        # run face detection model on a camera stream\n",
    "        for face in face_det_model.predict_batch(mytools.video_source(stream)):\n",
    "            # prepare list of bboxes of detected faces\n",
    "            if not face.results:\n",
    "                continue\n",
    "\n",
    "            # prepare generator of images cropped around each detected face\n",
    "            face_crops = ( mytools.Display.crop(face.image, f['bbox']) for f in face.results )\n",
    "\n",
    "            # for each detected face detect the mask presence\n",
    "            for masks, face_result in zip(mask_det_model.predict_batch(face_crops), face.results):\n",
    "                for r in masks.results: # apply mask presence label\n",
    "                    face_result[\"label\"] = r[\"label\"]\n",
    "\n",
    "            display.show(face.image_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15f39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f77ba0ef977241afac66801d7297b5fb2ffa6cc21668a24d017a9f23b5f689e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
