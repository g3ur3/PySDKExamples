{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f257328f",
   "metadata": {},
   "source": [
    "## Example script illustrating sound classification on audio stream\n",
    "This notebook is an example how to use DeGirum PySDK to do sound classification AI inference of an audio stream from local microphone.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. [DeGirum Cloud Platform](https://cs.degirum.com),\n",
    "1. DeGirum-hosted AI server node shared via Peer-to-Peer VPN,\n",
    "1. AI server node hosted by you in your local network,\n",
    "1. AI server running on your local machine,\n",
    "1. DeGirum ORCA accelerator directly installed on your local machine.\n",
    "\n",
    "To try different options, you just need to change the `inference_option` in the code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9de969",
   "metadata": {},
   "source": [
    "### Specify where do you want to run your inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9c22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_option = 1  # <<< change it according to your needs selecting from the list in the header comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28225e3a",
   "metadata": {},
   "source": [
    "### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5a1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import mytools\n",
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "if sys.platform == \"darwin\":\n",
    "    raise \"Sorry, MacOS is currently not supported due to problems with pyaudio package\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ee6c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference option = 'DeGirum Cloud Platform'\n"
     ]
    }
   ],
   "source": [
    "# connect to model zoo according to selected inference option\n",
    "zoo = mytools.connect_model_zoo(inference_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3dd775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load YAMNET sound classification model for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "model = zoo.load_model(\"mobilenet_v1_yamnet_sound_cls--96x64_quant_n2x_orca_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee28b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-specific audio streaming function\n",
    "# TL;DR: \n",
    "# We define context manager function, which opens PyAudio stream on enter, reads it and yields audio waveforms\n",
    "# of proper type, proper size, and with proper overlap. It properly closes PyAudio stream on exit.\n",
    "# You pass model parameters and check-for-abort function as arguments.\n",
    "\n",
    "import pyaudio\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager \n",
    "def AudioStream(model_info, check_abort):\n",
    "    chunk_length = model_info.InputWaveformSize[0] // 2\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format = pyaudio.paInt16, channels = 1,\n",
    "            rate = int(model_info.InputSamplingRate[0]), input = True, frames_per_buffer = chunk_length)\n",
    "    \n",
    "    data = np.zeros(2 * chunk_length, dtype = np.int16)\n",
    "    try:\n",
    "        def out_stream():\n",
    "            while not check_abort():\n",
    "                data[:chunk_length] = data[chunk_length:]\n",
    "                data[chunk_length:] = np.frombuffer(stream.read(chunk_length), dtype = np.int16)\n",
    "                yield data\n",
    "        yield out_stream\n",
    "    finally:\n",
    "        stream.stop_stream() # stop audio streaming\n",
    "        stream.close() # close audio stream\n",
    "        audio.terminate() # terminate audio library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db989e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "abort = False # stream abort flag\n",
    "N = 5 # inference results history depth\n",
    "history = [] # list of N consecutive inference results\n",
    "\n",
    "# Acquire model input stream object\n",
    "with AudioStream(model.model_info, lambda: abort) as stream:\n",
    "    #\n",
    "    # AI prediction loop.\n",
    "    # emit keyboard typing sound to stop\n",
    "    #\n",
    "    for res in model.predict_batch(stream()):\n",
    "        # clear Jupyter output cell\n",
    "        clear_output(wait = True) \n",
    "        \n",
    "        # add top inference result to history\n",
    "        history.insert(0, f\"{res.results[0]['label']}: {res.results[0]['score']}\" )\n",
    "    \n",
    "        # keep only N last elements in history\n",
    "        if len(history) > N:\n",
    "            history.pop()\n",
    "    \n",
    "        # print history\n",
    "        for m in history:\n",
    "            print(m)\n",
    "        \n",
    "        # check for stop condition\n",
    "        if res.results[0]['label'] == \"Typing\":\n",
    "            abort = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d58c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
