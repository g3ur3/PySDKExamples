{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f257328f",
   "metadata": {},
   "source": [
    "## Example script illustrating sound classification on audio stream\n",
    "This notebook is an example how to use DeGirum PySDK to do sound classification AI inference of an audio stream from local microphone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import mytools\n",
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782a69f",
   "metadata": {},
   "source": [
    "### Specify inference option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee6c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment and edit one of the following inference options to specify your system configuration case according to\n",
    "# https://cs.degirum.com/doc/0.5.0/degirum.html#system-configuration-for-specific-use-cases\n",
    "\n",
    "# 1. DeGirum Cloud Zoo inference:\n",
    "#zoo = dg.connect_model_zoo(\"dgcps://cs.degirum.com\", token=mytools.token_get())\n",
    "\n",
    "# 2. AIServer inference via IP address using models from DeGirum Cloud model zoo\n",
    "#zoo = dg.connect_model_zoo((\"192.168.0.7\", \"https://cs.degirum.com/degirum_com/public\"), token=mytools.token_get())\n",
    "\n",
    "# 3. AIServer inference via IP address using local model zoo\n",
    "#zoo = dg.connect_model_zoo(\"192.168.0.1\")\n",
    "\n",
    "# 4. ORCA board installed locally using models from DeGirum Cloud Model Zoo\n",
    "#zoo = dg.connect_model_zoo(\"https://cs.degirum.com/degirum_com/public\", token=mytools.token_get())\n",
    "\n",
    "# 5. Local inference with locally deployed model\n",
    "#zoo = dg.connect_model_zoo(\"full/path/to/model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load YAMNET sound classification model for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "model = zoo.load_model(\"mobilenet_v1_yamnet_sound_cls--96x64_quant_n2x_orca_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db989e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "abort = False # stream abort flag\n",
    "N = 5 # inference results history depth\n",
    "history = [] # list of N consecutive inference results\n",
    "\n",
    "sampling_rate_hz = model.model_info.InputSamplingRate[0]\n",
    "read_buffer_size = model.model_info.InputWaveformSize[0] // 2 # two read buffers in waveform for half-length overlapping\n",
    "\n",
    "# Acquire model input stream object\n",
    "with mytools.open_audio_stream(sampling_rate_hz, read_buffer_size) as stream:\n",
    "    #\n",
    "    # AI prediction loop.\n",
    "    # emit keyboard typing sound to stop\n",
    "    #\n",
    "    for res in model.predict_batch(mytools.audio_overlapped_source(stream, lambda: abort)):\n",
    "        # clear Jupyter output cell\n",
    "        clear_output(wait = True) \n",
    "        \n",
    "        # add top inference result to history\n",
    "        history.insert(0, f\"{res.results[0]['label']}: {res.results[0]['score']}\" )\n",
    "    \n",
    "        # keep only N last elements in history\n",
    "        if len(history) > N:\n",
    "            history.pop()\n",
    "    \n",
    "        # print history\n",
    "        for m in history:\n",
    "            print(m)\n",
    "        \n",
    "        # check for stop condition\n",
    "        if res.results[0]['label'] == \"Typing\":\n",
    "            abort = True\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
