{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiwV0wCyxMOw"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install --quiet degirum\n",
        "!curl -s https://cdn.pixabay.com/photo/2018/04/05/17/22/kettlebell-3293481_1280.jpg -o ThreePersons.jpg\n",
        "!pip install --ignore-installed Pillow==9.2.0\n",
        "# Restart runtime when prompted\n",
        "# skip the current cell and proceed to next after restart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9dqb-9Qxunl"
      },
      "outputs": [],
      "source": [
        "import degirum as dg\n",
        "\n",
        "zoo = dg.connect(dg.CLOUD, 'https://cs.degirum.com/degirum/public', '<your cloud token>')\n",
        "model = zoo.load_model('yolo_v5s_coco--512x512_quant_n2x_orca_1')\n",
        "model.measure_time = True\n",
        "res = model('ThreePersons.jpg')\n",
        "res.image_overlay\n",
        "# model predictions\n",
        "# res.results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats = model.time_stats()\n",
        "print(\"{:<27} - {}\".format(\"PythonPreprocessDuration_ms\", stats[\"PythonPreprocessDuration_ms\"].avg))\n",
        "print(\"{:<27} - {}\".format(\"CoreInferenceDuration_ms\", stats[\"CoreInferenceDuration_ms\"].avg))\n",
        "print(\"{:<27} - {}\".format(\"CoreLoadResultDuration_ms\", stats[\"CoreLoadResultDuration_ms\"].avg))\n",
        "print(\"{:<27} - {}\".format(\"CorePostprocessDuration_ms\", stats[\"CorePostprocessDuration_ms\"].avg))\n",
        "print(\"{:<27} - {}\".format(\"CorePreprocessDuration_ms\", stats[\"CorePreprocessDuration_ms\"].avg))\n",
        "print(\"{:<27} - {}\".format(\"FrameTotalDuration_ms\", stats[\"FrameTotalDuration_ms\"].avg))"
      ],
      "metadata": {
        "id": "xjB_zcs1LYKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWEIZPYc8vYK"
      },
      "outputs": [],
      "source": [
        "# list all AI models available for inference\n",
        "zoo.list_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of how to pipeline two models\n",
        "**Face Mask Detection Pipelined**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ylQNVwvrW8lC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GXwl04qBkxJ"
      },
      "outputs": [],
      "source": [
        "# load models for DeGirum Orca AI accelerator\n",
        "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
        "face_det_model = zoo.load_model(\"yolo_v5s_face_det--512x512_quant_n2x_orca_1\")\n",
        "mask_det_model = zoo.load_model(\"mobilenet_v2_mask_yn_cls--224x224_float_n2x_orca_1\")\n",
        "\n",
        "# adjust some model properties\n",
        "face_det_model.output_confidence_threshold = 0.7\n",
        "face_det_model.overlay_font_scale = 1.5\n",
        "face_det_model.overlay_alpha = 1\n",
        "face_det_model.image_backend = 'pil'\n",
        "mask_det_model.overlay_show_labels = True\n",
        "mask_det_model.overlay_font_scale = 1.5\n",
        "mask_det_model.overlay_alpha = 1\n",
        "mask_det_model.output_top_k = 1\n",
        "mask_det_model.image_backend = 'pil'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# detect persons\n",
        "!curl -s https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/Mask1.jpg -o Mask1.jpg\n",
        "faces = face_det_model('Mask1.jpg')\n",
        "\n",
        "# for each detected face detect mask\n",
        "with mask_det_model: # performance optimization to keep connection to mask_det_model open\n",
        "    for face in faces.results:\n",
        "        face_box = faces.image.crop(face['bbox'])\n",
        "        mask = mask_det_model(face_box)\n",
        "        face[\"label\"] = mask.results[0][\"label\"]\n",
        "        display(mask.image_overlay)\n",
        "\n",
        "# display combined results\n",
        "display(faces.image_overlay)"
      ],
      "metadata": {
        "id": "p5HbFZK7V0-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**License Plate Detection & Recognition Pipelined**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NIY5DvnwXe9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load models for DeGirum Orca AI accelerator\n",
        "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
        "lp_det_model = zoo.load_model(\"yolo_v5s_lp_det--512x512_quant_n2x_orca_1\")\n",
        "lp_ocr_model = zoo.load_model(\"yolo_v5s_lp_ocr--256x256_quant_n2x_orca_1\")\n",
        "\n",
        "# adjust some model properties\n",
        "lp_det_model.output_confidence_threshold = 0.7\n",
        "lp_det_model.overlay_font_scale = 1.5\n",
        "lp_det_model.overlay_alpha = 1\n",
        "lp_det_model.image_backend = 'pil'\n",
        "lp_ocr_model.overlay_show_labels = True\n",
        "lp_ocr_model.overlay_font_scale = 1.5\n",
        "lp_ocr_model.overlay_alpha = 1\n",
        "lp_ocr_model.output_top_k = 1\n",
        "lp_ocr_model.image_backend = 'pil'"
      ],
      "metadata": {
        "id": "9p6g3ECAXfET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detect license plates\n",
        "!curl -s https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/Car.jpg -o Car.jpg\n",
        "license_plates = lp_det_model('Car.jpg')\n",
        "\n",
        "# for each detected license place detect  characters\n",
        "with lp_det_model: # performance optimization to keep connection to lp_det_model open\n",
        "    for plate in license_plates.results:\n",
        "        lp_box = license_plates.image.crop(plate['bbox'])\n",
        "        ocr_plates = lp_ocr_model(lp_box)\n",
        "        plate[\"label\"] = ocr_plates.results[0][\"label\"]\n",
        "        display(ocr_plates.image_overlay)\n",
        "\n",
        "# display combined results\n",
        "display(license_plates.image_overlay)"
      ],
      "metadata": {
        "id": "UR2jrxHDXgPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object Detection on Video**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AJBns2UfpwLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLbTR1g7AVXb"
      },
      "outputs": [],
      "source": [
        "!curl -s https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/Traffic.mp4 -o Traffic.mp4\n",
        "!curl -s https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/mytools.py -o mytools.py\n",
        "\n",
        "import cv2\n",
        "import degirum as dg, mytools\n",
        "from IPython.display import HTML\n",
        "from pathlib import Path\n",
        "from base64 import b64encode\n",
        "\n",
        "zoo = dg.connect(dg.CLOUD, 'https://cs.degirum.com/degirum/public', 'dg_CAMfjDcMpgUGsXzkSYqdLAA2CJQHvH95yu4Bk')\n",
        "model = zoo.load_model('yolo_v5s_coco--512x512_quant_n2x_orca_1')\n",
        "model.image_backend = 'opencv' # select OpenCV backend: needed to have overlay image in OpenCV format\n",
        "model.input_numpy_colorspace = 'BGR'\n",
        "model.overlay_show_probabilities = True\n",
        "model.overlay_line_width = 1\n",
        "model._model_parameters.InputImgFmt = ['JPEG']\n",
        "\n",
        "orig_path = Path('Traffic.mp4')\n",
        "ann_path = orig_path.with_name(orig_path.stem + '_annotated' + orig_path.suffix)\n",
        "\n",
        "# AI prediction loop\n",
        "# Press 'x' or 'q' to stop\n",
        "with mytools.Display('AI Camera') as display, \\\n",
        "     mytools.open_video_stream('Traffic.mp4') as stream, \\\n",
        "     mytools.open_video_writer(str(ann_path), stream.get(cv2.CAP_PROP_FRAME_WIDTH), stream.get(cv2.CAP_PROP_FRAME_HEIGHT)) as writer:\n",
        "\n",
        "    progress = mytools.Progress(int(stream.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "    for res in model.predict_batch(mytools.video_source(stream, report_error=False)):\n",
        "        img = res.image_overlay\n",
        "        # writer.write(img)\n",
        "        progress.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZVtZp7qBexs"
      },
      "outputs": [],
      "source": [
        "# view procession video\n",
        "mp4 = open(ann_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=800 controls><source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}