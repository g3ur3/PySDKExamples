{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62a2ee2",
   "metadata": {},
   "source": [
    "## Examples of `mystreams` module usage \n",
    "\n",
    "This notebook contains various examples, which demonstrate the capabilities of `mystreams` module: streaming toolkit for PySDK.\n",
    "\n",
    "The script also uses either a web camera or local camera connected to the machine running this code. The camera index or URL needs to be specified in [env.ini](env.ini) file by defining `CAMERA_ID` variable. If not specified, default local camera will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077ac0e",
   "metadata": {},
   "source": [
    "### Simplest example: video source is connected to video display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008ada1-9b55-4739-aa0c-0e48370625db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystreams import *\n",
    "\n",
    "# create Composition: an object, which keeps all streaming blocks (called gizmos) and runs them in parallel\n",
    "c = Composition()\n",
    "\n",
    "# create gizmos:\n",
    "source = VideoSourceGizmo()  # video source gizmo\n",
    "display = VideoDisplayGizmo(\n",
    "    \"press `x` or `q` to stop\", allow_drop=False\n",
    ")  # video display gizmo\n",
    "\n",
    "# Create pipeline: connect display input to source output\n",
    "display.connect_to(source)\n",
    "\n",
    "# add gizmos to composition\n",
    "c.add(source)\n",
    "c.add(display)\n",
    "\n",
    "# start composition\n",
    "c.start()\n",
    "\n",
    "# call c.stop() to stop composition or just press `x` or `q` in display window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c57054",
   "metadata": {},
   "source": [
    "### Same example, but with compact syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83524ee-f48d-469a-addf-0642f23b1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystreams import *\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "# Create gizmos and pipeline as a single-liner:\n",
    "# we use __call__() operator of Composition class instead of add() method\n",
    "# and we use `>>` operator of gizmo classes instead of connect_to() method\n",
    "c(VideoSourceGizmo()) >> c(VideoDisplayGizmo())\n",
    "\n",
    "c.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00314218",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of forked streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71adfe-b317-4bd3-ad08-564d10af6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystreams import *\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "# create and add to composition all required gizmos\n",
    "source = c.add(VideoSourceGizmo())  # video source gizmo\n",
    "display = c.add(\n",
    "    VideoDisplayGizmo([\"Original\", \"Resized\"])\n",
    ")  # two-input display gizmo: will show two windows\n",
    "resizer = c.add(ResizingGizmo(300, 200))  # resizing gizmo\n",
    "\n",
    "# Create pipeline: the image source is fed to a display and to the image resizing gizmo,\n",
    "# which is then fed to another display.\n",
    "\n",
    "display.connect_to(source, 0)  # display input 0 is \"Original\"\n",
    "resizer.connect_to(source)\n",
    "display.connect_to(resizer, 1)  # display input 1 is \"Resized\"\n",
    "\n",
    "c.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7b1d0-5cd7-4020-84b4-a2cd0dfec911",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of capturing video input into file with simultaneous display on a screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a77196-f465-495b-b511-65a10ae15b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystreams import *\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "source = c.add(VideoSourceGizmo())\n",
    "display = c.add(VideoDisplayGizmo())\n",
    "saver = c.add(VideoSaverGizmo(\"mycapture.mp4\"))\n",
    "\n",
    "source >> display\n",
    "source >> saver\n",
    "\n",
    "c.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09275e-8fb5-47b8-911f-6cd625680556",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of AI inference from the camera with AI inference results display\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you just need to uncomment **one** of the lines in the code below.\n",
    "\n",
    "You also need to specify your cloud API access token, cloud zoo URLs, and AI server hostname in [env.ini](env.ini) file, located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236df882-756f-481e-bb28-f4290286b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, mytools\n",
    "\n",
    "cloud_token = mytools.get_token()  # get cloud API access token from env.ini file\n",
    "cloud_zoo_url = mytools.get_cloud_zoo_url()  # get cloud zoo URL from env.ini file\n",
    "\n",
    "#\n",
    "# Please UNCOMMENT only ONE of the following lines to specify where to run AI inference\n",
    "#\n",
    "\n",
    "# 1. Inference on the DeGirum Cloud Platform\n",
    "zoo = dg.connect_model_zoo(\"dgcps://cs.degirum.com\" + cloud_zoo_url, cloud_token)\n",
    "\n",
    "# 2. Inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN\n",
    "# zoo = dg.connect_model_zoo((mytools.get_ai_server_hostname(), \"https://cs.degirum.com\" + cloud_zoo_url), cloud_token)\n",
    "\n",
    "# 3. Inference on DeGirum ORCA accelerator installed on your computer\n",
    "# zoo = dg.connect_model_zoo(\"https://cs.degirum.com\" + cloud_zoo_url, cloud_token)\n",
    "\n",
    "\n",
    "from mystreams import *\n",
    "\n",
    "# load some object detection AI model\n",
    "model = zoo.load_model(\"yolo_v5s_coco--512x512_quant_n2x_orca_1\")\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "# create gizmos\n",
    "source = c.add(VideoSourceGizmo())  # video source\n",
    "detection = c.add(AiSimpleGizmo(model))  # AI model\n",
    "display = c.add(\n",
    "    VideoDisplayGizmo(\"Detection\", show_ai_overlay=True, show_fps=True)\n",
    ")  # display\n",
    "\n",
    "# create pipeline\n",
    "source >> detection >> display\n",
    "\n",
    "c.start()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3eadf612-390e-4cd4-9dc3-94fd77b3869c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of AI inference with separate pre-processing stage\n",
    "\n",
    "Frames from the camera are supplied to the object detection model preprocessor and then to the object detection model\n",
    "itself. This improves performance to let image resizing preprocessor running is separate thread.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you just need to uncomment **one** of the lines in the code below.\n",
    "\n",
    "You also need to specify your cloud API access token, cloud zoo URLs, and AI server hostname in [env.ini](env.ini) file, located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608dd98-f64e-4a8e-b862-0f378f877cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, mytools\n",
    "\n",
    "cloud_token = mytools.get_token()  # get cloud API access token from env.ini file\n",
    "cloud_zoo_url = mytools.get_cloud_zoo_url()  # get cloud zoo URL from env.ini file\n",
    "\n",
    "#\n",
    "# Please UNCOMMENT only ONE of the following lines to specify where to run AI inference\n",
    "#\n",
    "\n",
    "# 1. Inference on the DeGirum Cloud Platform\n",
    "zoo = dg.connect_model_zoo(\"dgcps://cs.degirum.com\" + cloud_zoo_url, cloud_token)\n",
    "\n",
    "# 2. Inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN\n",
    "# zoo = dg.connect_model_zoo((mytools.get_ai_server_hostname(), \"https://cs.degirum.com\" + cloud_zoo_url), cloud_token)\n",
    "\n",
    "# 3. Inference on DeGirum ORCA accelerator installed on your computer\n",
    "# zoo = dg.connect_model_zoo(\"https://cs.degirum.com\" + cloud_zoo_url, cloud_token)\n",
    "\n",
    "\n",
    "from mystreams import *\n",
    "\n",
    "# load AI model\n",
    "model = zoo.load_model(\"yolo_v5s_coco--512x512_quant_n2x_orca_1\")\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "# create gizmos\n",
    "source = c.add(VideoSourceGizmo())  # video source\n",
    "preprocessor = c.add(AiPreprocessGizmo(model))\n",
    "detection = c.add(AiSimpleGizmo(model))\n",
    "display = c.add(VideoDisplayGizmo(\"Objects\", show_ai_overlay=True, show_fps=True))  # display\n",
    "\n",
    "# create pipeline\n",
    "source >> preprocessor >> detection >> display\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe873638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
